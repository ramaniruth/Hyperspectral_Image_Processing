{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JigsawHSI for Hyper Spectral Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'PU_100'\n",
    "# dataset = 'IP_99.74'\n",
    "# dataset = 'PU_100'\n",
    "# dataset = 'SA_100'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp39-cp39-win_amd64.whl (455.9 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ReadTimeoutError(\"HTTPSConnectionPool(host='pypi.org', port=443): Read timed out. (read timeout=15)\")': /simple/tensorflow-estimator/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: h5py>=2.9.0 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-1.3.0-py3-none-any.whl (124 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "Requirement already satisfied: setuptools in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: packaging in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in e:\\anaconda\\install\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in e:\\anaconda\\install\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in e:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in e:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in e:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in e:\\anaconda\\install\\lib\\site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in e:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in e:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in e:\\anaconda\\install\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in e:\\anaconda\\install\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in e:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in e:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in e:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in e:\\anaconda\\install\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.4)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in e:\\anaconda\\install\\lib\\site-packages (from packaging->tensorflow) (3.0.4)\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "Successfully installed absl-py-1.3.0 astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 oauthlib-3.2.1 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize all random functions with same seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Use this before loading tensorflow\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '1' # Block INFO messages\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # Block INFO and WARNING messages\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # Block INFO, WARNING and ERROR messages\n",
    "# https://www.tensorflow.org/api_docs/python/tf/autograph/set_verbosity\n",
    "os.environ[\"AUTOGRAPH_VERBOSITY\"] = \"0\"\n",
    "import tensorflow as tf\n",
    "tf.get_logger().setLevel(\"WARNING\")\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def random_seed():\n",
    "    return os.urandom(42)\n",
    "\n",
    "def reset_seeds(random_state = 42):\n",
    "    try:\n",
    "        tf.keras.utils.set_random_seed(random_state) # This resets all\n",
    "        return 0\n",
    "    except:\n",
    "        random.seed(random_state)\n",
    "        np.random.seed(random_state)\n",
    "        tf.random.set_seed(random_state) # Tensorflow 2.9+\n",
    "    try:\n",
    "        from tensorflow import set_random_seed # Tensorflow 1.x\n",
    "        set_random_seed(random_state)\n",
    "        return 2\n",
    "    except:\n",
    "        pass\n",
    "    return 1\n",
    "\n",
    "max_gpus = len(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\"\"\"\n",
    "Reset all random seeds\n",
    "\"\"\"\n",
    "r = reset_seeds(345)\n",
    "del r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "executionInfo": {
     "elapsed": 5572,
     "status": "ok",
     "timestamp": 1602478409232,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r9imWZNCMoOM",
    "outputId": "e6ddc3e2-53c3-4e29-ceb6-5b303ac0b75b"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis, NMF\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from operator import truediv\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "\n",
    "#!pip install spectral\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JigsawHSI definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5565,
     "status": "ok",
     "timestamp": 1602478409233,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HC83Bv1IPQfc"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Flatten, Dropout, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adadelta, SGD, Adam, Nadam, Adagrad, Adamax\n",
    "\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras import utils as np_utils\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import multi_gpu_model\n",
    "\n",
    "def jigsaw_m2( input_net, first_layer = None , internal_size = 13):\n",
    "    # Creates internal filters as Inception: 1x1, 3x3, 5x5 ..., nxn \n",
    "    # Where n = internal_size\n",
    "    jigsaw_t1_1x1 = Conv2D(256, (1,1), padding='same', activation = 'relu', \n",
    "                           kernel_regularizer = l2(0.002))(input_net)\n",
    "    jigsaw_t1_3x3_reduce = Conv2D(96, (1,1), padding='same', activation = 'relu', \n",
    "                                  kernel_regularizer = l2(0.002))(input_net)\n",
    "    jigsaw_t1_3x3 = Conv2D(128, (3,3), padding='same', activation = 'relu', \n",
    "                           kernel_regularizer = l2(0.002))(jigsaw_t1_3x3_reduce) # , name=\"i_3x3\"\n",
    "    if (internal_size >= 5):\n",
    "        jigsaw_t1_5x5_reduce = Conv2D(16, (1,1), padding='same', activation = 'relu', \n",
    "                                      kernel_regularizer = l2(0.002))(input_net)\n",
    "        jigsaw_t1_5x5 = Conv2D(128, (5,5), padding='same', activation = 'relu', \n",
    "                               kernel_regularizer = l2(0.002))(jigsaw_t1_5x5_reduce) # , name=\"i_5x5\"\n",
    "    if (internal_size >= 7):\n",
    "        jigsaw_t1_7x7_reduce = Conv2D(16, (1,1), padding='same', activation = 'relu', \n",
    "                                      kernel_regularizer = l2(0.002))(input_net)\n",
    "        jigsaw_t1_7x7 = Conv2D(128, (7,7), padding='same', activation = 'relu', \n",
    "                               kernel_regularizer = l2(0.002))(jigsaw_t1_7x7_reduce) # , name=\"i_7x7\"\n",
    "    if (internal_size >= 9):\n",
    "        jigsaw_t1_9x9_reduce = Conv2D(16, (1,1), padding='same', activation = 'relu', \n",
    "                                      kernel_regularizer = l2(0.002))(input_net)\n",
    "        jigsaw_t1_9x9 = Conv2D(64, (9,9), padding='same', activation = 'relu', \n",
    "                               kernel_regularizer = l2(0.002))(jigsaw_t1_9x9_reduce) # , name=\"i_9x9\"\n",
    "    if (internal_size >= 11):\n",
    "        jigsaw_t1_11x11_reduce = Conv2D(16, (1,1), padding='same', activation = 'relu', \n",
    "                                        kernel_regularizer = l2(0.002))(input_net)\n",
    "        jigsaw_t1_11x11 = Conv2D(64, (11,11), padding='same', activation = 'relu', \n",
    "                                 kernel_regularizer = l2(0.002))(jigsaw_t1_11x11_reduce) # , name=\"i_11x11\"\n",
    "    if (internal_size >= 13):\n",
    "        jigsaw_t1_13x13_reduce = Conv2D(16, (1,1), padding='same', activation = 'relu', \n",
    "                                        kernel_regularizer = l2(0.002))(input_net)\n",
    "        jigsaw_t1_13x13 = Conv2D(64, (13,13), padding='same', activation = 'relu', \n",
    "                                 kernel_regularizer = l2(0.002))(jigsaw_t1_13x13_reduce) # , name=\"i_13x13\"\n",
    "    jigsaw_t1_pool = MaxPooling2D(pool_size=(3,3), strides = (1,1), padding='same')(input_net)\n",
    "    jigsaw_t1_pool_proj = Conv2D(32, (1,1), padding='same', activation = 'relu', \n",
    "                                 kernel_regularizer = l2(0.002))(jigsaw_t1_pool)\n",
    "    jigsaw_list = [jigsaw_t1_1x1, jigsaw_t1_3x3]\n",
    "    if (internal_size >= 5):\n",
    "        jigsaw_list.append(jigsaw_t1_5x5)\n",
    "    if (internal_size >= 7):\n",
    "        jigsaw_list.append(jigsaw_t1_7x7)\n",
    "    if (internal_size >= 9):\n",
    "        jigsaw_list.append(jigsaw_t1_9x9)\n",
    "    if (internal_size >= 11):\n",
    "        jigsaw_list.append(jigsaw_t1_11x11)\n",
    "    if (internal_size >= 13):\n",
    "        jigsaw_list.append(jigsaw_t1_13x13)\n",
    "    jigsaw_list.append(jigsaw_t1_pool_proj)\n",
    "    if first_layer is not None:\n",
    "        jigsaw_t1_first = Conv2D(96, (1,1), padding='same', activation = 'relu', \n",
    "                                 kernel_regularizer = l2(0.002))(first_layer)\n",
    "        jigsaw_list.append(jigsaw_t1_first)\n",
    "    jigsaw_t1_output = Concatenate(axis = -1)(jigsaw_list)\n",
    "    return jigsaw_t1_output\n",
    "\n",
    "def jigsaw_m_end(input_net, num_classes, first_layer = None):\n",
    "    avg_pooling = AveragePooling2D(pool_size=(3,3), strides=(1,1), name='avg_pooling')(input_net)\n",
    "    flat = Flatten()(avg_pooling)\n",
    "    flat = Dense(16, kernel_regularizer=l2(0.002))(flat)\n",
    "    flat = Dropout(0.4)(flat)\n",
    "    if first_layer is not None:\n",
    "        input_pixel = Flatten()(first_layer)\n",
    "        input_pixel = Dense(16, kernel_regularizer=l2(0.002))(input_pixel)\n",
    "        input_pixel = Dropout(0.2)(input_pixel)\n",
    "        input_pixel = Dense(16, kernel_regularizer=l2(0.002))(input_pixel)\n",
    "        input_pixel = Dropout(0.2)(input_pixel)\n",
    "        flat = Concatenate(axis = -1)([input_pixel, flat])\n",
    "    flat = Dense(32, kernel_regularizer=l2(0.002))(flat)\n",
    "    avg_pooling = Dropout(0.4)(flat)\n",
    "    loss3_classifier = Dense(num_classes, kernel_regularizer=l2(0.002))(avg_pooling)\n",
    "    loss3_classifier_act = Activation('softmax', name='prob')(loss3_classifier)\n",
    "    return loss3_classifier_act\n",
    "\n",
    "\n",
    "# Builds model\n",
    "def build_jigsawHSI(internal_size=13, num_classes=2, image_dim = (19, 19, 7), dimension_filters = None, verbose=1):\n",
    "    my_input = Input( shape=image_dim )\n",
    "    \n",
    "    # Not needed for SA\n",
    "    if ((dimension_filters is None) or (dimension_filters < 1)):\n",
    "        conv1 = None\n",
    "    else:\n",
    "        conv1 = Conv2D(dimension_filters, (1,1), padding='same', activation = 'relu',\n",
    "                      kernel_regularizer = l2(0.002), name='spectral_filter')(my_input)\n",
    "    if(verbose>0):\n",
    "        print(f\"*** Building Jigsaw with up to {internal_size}x{internal_size} kernels\")\n",
    "    # One jigsaw module(s)\n",
    "    jigsaw_01 = jigsaw_m2( my_input if conv1 is None else conv1, internal_size = internal_size )\n",
    "    # For SA, the next two lines must be uncommented\n",
    "    # jigsaw_01 = jigsaw_m2( jigsaw_01, first_layer=my_input, internal_size = internal_size )\n",
    "    # jigsaw_01 = jigsaw_m2( jigsaw_01, internal_size = internal_size )\n",
    "    \n",
    "    # Attaches end to jigsaw modules, returns class within num_classes\n",
    "    loss3_classifier_act = jigsaw_m_end(jigsaw_01,\n",
    "                                    num_classes = num_classes,\n",
    "                                    first_layer = my_input ) # testing num_classes\n",
    "    model3 = Model( inputs = my_input, outputs = loss3_classifier_act )\n",
    "    model3.compile(loss='binary_crossentropy', optimizer=Adadelta(), metrics=['accuracy'])\n",
    "    return model3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel3D:\n",
    "    def __init__(self, rows=3, cols=3, shape='rect', radius=None, no_value=np.NaN):\n",
    "        if shape == 'circle':\n",
    "            self.rows = 2*radius+1\n",
    "            self.cols = 2*radius+1\n",
    "            self.mask = self.round_mask(radius)\n",
    "            self.row_buffer = radius\n",
    "            self.col_buffer = radius\n",
    "        else:\n",
    "            self.rows = rows\n",
    "            self.cols = cols\n",
    "            self.mask = np.ones((rows, cols))\n",
    "            self.row_buffer = int((rows-1)/2)\n",
    "            self.col_buffer = int((cols-1)/2)\n",
    "        self.mask = self.mask[np.newaxis, :, :]\n",
    "        self.no_value = no_value\n",
    "        assert((rows%2) == 1)\n",
    "        assert((cols%2) == 1)\n",
    "\n",
    "    def round_mask(self, radius):\n",
    "        diameter = 2*radius+1\n",
    "        mask = np.empty((diameter, diameter,))\n",
    "        mask[:] = self.no_value\n",
    "        sq_radius = radius**2\n",
    "        for i in range(diameter):\n",
    "            for j in range(diameter):\n",
    "                if ((i-radius)**2+(j-radius)**2) <= sq_radius:\n",
    "                    mask[i, j] = 1\n",
    "        return mask\n",
    "\n",
    "    def getSubset(self, matrix, row, column):\n",
    "        m_rows = matrix.shape[1]\n",
    "        assert (row >= self.row_buffer), f\"Out of bounds row {row}, from {m_rows}\"\n",
    "        assert (row < (m_rows-self.row_buffer)), f\"Out of bounds row {row}, from {m_rows}\"\n",
    "        m_cols = matrix.shape[2]\n",
    "        assert((column >= self.col_buffer) and (column < (m_cols-self.col_buffer))), f\"Out of bounds column {column}, from {m_cols}\"\n",
    "        row_start = row-self.row_buffer\n",
    "        row_end = row+self.row_buffer\n",
    "        column_start = column-self.col_buffer\n",
    "        column_end = column+self.col_buffer\n",
    "        small_matrix = matrix[:, row_start:row_end+1, column_start:column_end+1]\n",
    "        return small_matrix*self.mask\n",
    "\n",
    "class GeoTiffSlicer(object):\n",
    "    def __init__(self, land_matrix, kernel_rows=None, kernel_cols=None,\n",
    "                 kernel_shape='rect', kernel_radius=0, no_value = np.NaN):\n",
    "        # (w, h, d) input tiff expected\n",
    "        # (d, h, w) input tiff from rasterio must be transposed before calling this class\n",
    "        if kernel_cols is None:\n",
    "            kernel_cols = kernel_rows\n",
    "        assert(kernel_cols < land_matrix.shape[2])\n",
    "        assert(kernel_rows < land_matrix.shape[1])\n",
    "        assert((kernel_shape == 'rect') or (kernel_shape == 'circle'))\n",
    "        assert(kernel_radius>=0)\n",
    "        if kernel_shape == 'rect':\n",
    "            self.kernel = Kernel3D(rows=kernel_rows, cols=kernel_cols)\n",
    "        else:\n",
    "            self.kernel = Kernel3D(radius=kernel_radius,\n",
    "                                   shape=kernel_shape,\n",
    "                                   no_value=no_value)\n",
    "            kernel_rows = kernel_cols = 2*kernel_radius+1\n",
    "        self.kernel_rows = kernel_rows\n",
    "        self.kernel_cols = kernel_cols\n",
    "        self.land_matrix = land_matrix\n",
    "        self.land_matrix_channels, self.land_matrix_cols, self.land_matrix_rows = land_matrix.shape\n",
    "        self.land_matrix_cols = land_matrix.shape[2]\n",
    "        self.land_matrix_rows = land_matrix.shape[1]\n",
    "        self.land_matrix_channels = land_matrix.shape[0]\n",
    "        self.small_row_min = self.kernel.row_buffer\n",
    "        self.small_row_max = self.land_matrix_rows - self.small_row_min\n",
    "        self.small_column_min = self.kernel.col_buffer\n",
    "        self.small_column_max = self.land_matrix_cols - self.small_column_min\n",
    "\n",
    "    def apply_mask(self, row, column):\n",
    "        return self.kernel.getSubset(self.land_matrix, row=row, column=column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decompostion functions: reduce dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5559,
     "status": "ok",
     "timestamp": 1602478409234,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "UGivdxXN1pCh"
   },
   "outputs": [],
   "source": [
    "# Dimensionality reduction algorithms\n",
    "def applyPCA(X, numComponents=75, random_state=0):\n",
    "    newX = np.reshape(X, (-1, X.shape[2])) # Reshape to columns for each band\n",
    "    pca = PCA(n_components=numComponents, whiten=True, random_state=random_state)\n",
    "    newX = pca.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, 'pca'\n",
    "\n",
    "def applyFA(X, numComponents=75, random_state=0):\n",
    "    newX = np.reshape(X, (-1, X.shape[2])) # Reshape to columns for each band\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=random_state)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, 'fa'\n",
    "\n",
    "def applySVD(X, numComponents=75, random_state=0):\n",
    "    newX = np.reshape(X, (-1, X.shape[2])) # Reshape to columns for each band\n",
    "    svd = TruncatedSVD(n_components=numComponents, random_state=random_state)\n",
    "    newX = svd.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, 'svd'\n",
    "\n",
    "def applyNMF(X, numComponents=75, random_state=0):\n",
    "    newX = np.reshape(X, (-1, X.shape[2])) # Reshape to columns for each band\n",
    "    nmf = NMF(n_components=numComponents, random_state=random_state)\n",
    "    newX = nmf.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, 'nmf'\n",
    "\n",
    "def applyNone(X, numComponents=75, random_state=0):\n",
    "    return X, 'None'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilitary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5550,
     "status": "ok",
     "timestamp": 1602478409236,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "7wXNSkhfM3gs"
   },
   "outputs": [],
   "source": [
    "def readData(dataset, data_path='./data'):\n",
    "    data_dict = {\n",
    "        'IP': ('Indian_pines_corrected.mat', 'indian_pines_corrected', 'Indian_pines_gt.mat', 'indian_pines_gt'),\n",
    "        'SA': ('Salinas_corrected.mat', 'salinas_corrected', 'Salinas_gt.mat', 'salinas_gt'),\n",
    "        'PU': ('PaviaU.mat', 'paviaU', 'PaviaU_gt.mat', 'paviaU_gt')\n",
    "    }\n",
    "    (X_1, X_2, y_1, y_2) = data_dict.get(dataset[0:2].upper())\n",
    "    X = sio.loadmat(os.path.join(data_path, X_1))[X_2]\n",
    "    y = sio.loadmat(os.path.join(data_path, y_1))[y_2]\n",
    "    \n",
    "    return (X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5545,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iaIzfkQ3NDvS"
   },
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5538,
     "status": "ok",
     "timestamp": 1602478409237,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M0he4FtONMU-"
   },
   "outputs": [],
   "source": [
    "# Padding functions\n",
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.pad(X, pad_width=((margin, margin),(margin, margin),(0, 0)), constant_values = 0)\n",
    "    return newX\n",
    "\n",
    "def padSymmetric(X, margin=2):\n",
    "    newX = np.pad(X, pad_width=((margin, margin),(margin, margin),(0, 0)), mode = 'symmetric')\n",
    "    return newX\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5533,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "l0wsTkhNNO04"
   },
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, window_size=8, removeZeroLabels = True):\n",
    "    margin = int((window_size-1) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], window_size, window_size, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin + 1 , c - margin:c + margin + 1]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load parameters from config file (config.ini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser(inline_comment_prefixes=';#')\n",
    "config.read_file(open('config.ini'))\n",
    "config = config[dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse parameters and hyper-parameters from config file\n",
    "\n",
    "test_ratio   = config.getfloat('test_ratio', 0.9)\n",
    "window_size  = config.getint('window_size', 25)\n",
    "num_channels = config.getint('num_channels', 3)\n",
    "output_units = config.getint('output_units', 16)\n",
    "\n",
    "filter_size  = config.getint('filter_size', 13)\n",
    "\n",
    "batch_size   = config.getint('batch_size', 30)\n",
    "max_epochs   = config.getint('max_epochs', 100)\n",
    "\n",
    "decomp_func  = config.get('decomp_func', 'pca').lower()\n",
    "optimizer_fn = config.get('optimizer_fn', 'sgd').lower()\n",
    "optimizer_lr = config.getfloat('optimizer_lr', 0.01)\n",
    "max_patience = config.getint('max_patience', 10)\n",
    "\n",
    "hsi_filters  = config.get('hsi_filters', 'none')\n",
    "hsi_filters  = None if (hsi_filters.lower() in ['none', '']) else int(hsi_filters)\n",
    "print(hsi_filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select proper optimizer and decomposition functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_reduction={\n",
    "    'fa' : (lambda X, numComponents: applyFA(X, numComponents=numComponents)),\n",
    "    'nmf' : (lambda X, numComponents: applyNMF(X, numComponents=numComponents)),\n",
    "    'pca': (lambda X, numComponents: applyPCA(X, numComponents=numComponents)),\n",
    "    'svd': (lambda X, numComponents: applySVD(X, numComponents=numComponents)),\n",
    "    'none': (lambda X, numComponents: applyNone(X, numComponents=numComponents))\n",
    "}\n",
    "\n",
    "DimReduction=dict_reduction.get(decomp_func)\n",
    "\n",
    "dict_optimizer = {\n",
    "    'sgd'     : SGD(learning_rate=optimizer_lr, momentum=0.9, nesterov=False),\n",
    "    'adadelta': Adadelta(learning_rate=optimizer_lr, rho=0.95, epsilon=1e-07),\n",
    "    'adam'    : Adam(learning_rate=optimizer_lr, epsilon=1e-07),\n",
    "    'nadam'   : Nadam(learning_rate=optimizer_lr, epsilon=1e-07),\n",
    "    'adamax'  : Adamax(learning_rate=optimizer_lr, epsilon=1e-07),\n",
    "    'adagrad' : Adagrad(learning_rate=optimizer_lr, epsilon=1e-07)\n",
    "}\n",
    "\n",
    "FuncOptimizer = dict_optimizer.get(optimizer_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define names of output files\n",
    "best_model          = dataset + '-best-model.hdf5'\n",
    "loss_curve          = dataset + '-loss-curve.png'\n",
    "acc_curve           = dataset + '-acc-curve.png'\n",
    "classification_file = dataset + '-classification_report.txt'\n",
    "predictions_img     = dataset + '-predictions.png'\n",
    "architecture_img    = dataset + '-architecture.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 5525,
     "status": "ok",
     "timestamp": 1602478409238,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "cnneGlFFNRVo",
    "outputId": "3b00138d-9d02-4b14-f6e2-2b1dc9ad8aeb"
   },
   "outputs": [],
   "source": [
    "HSI, HSI_y = readData(dataset[0:2].upper())\n",
    "\n",
    "HSI.shape, HSI_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5518,
     "status": "ok",
     "timestamp": 1602478409239,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "TOGl1BmWNdyv"
   },
   "outputs": [],
   "source": [
    "num_channels = np.min([HSI.shape[2], num_channels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 30165,
     "status": "ok",
     "timestamp": 1602478433894,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "fTYzjiltNj8a",
    "outputId": "7bfa99db-15b8-40d1-83b2-b7d32d039c0e"
   },
   "outputs": [],
   "source": [
    "DRI, dim_reduction = DimReduction(HSI,numComponents=num_channels)\n",
    "\n",
    "num_channels = DRI.shape[2]\n",
    "DRI.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31758,
     "status": "ok",
     "timestamp": 1602478435499,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "hiZiDsE0cN-O",
    "outputId": "acf836b7-666b-4104-c856-d4e0b1d1f84f"
   },
   "outputs": [],
   "source": [
    "X, y = createImageCubes(DRI, HSI_y, window_size=window_size)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31739,
     "status": "ok",
     "timestamp": 1602478435500,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OMYMZxnDcSHb",
    "outputId": "8e9b4564-aff1-40e2-b081-7154c18d5d77"
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31716,
     "status": "ok",
     "timestamp": 1602478435501,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "VBvWzipfcZDK",
    "outputId": "af402f16-e7ee-4272-c243-ae05646c8317"
   },
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.reshape(-1, window_size, window_size, num_channels) #, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 31703,
     "status": "ok",
     "timestamp": 1602478435502,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "lxr7HMjocZvd",
    "outputId": "cb12450a-7ffc-44a2-d57b-2e42e0402ec4"
   },
   "outputs": [],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31657,
     "status": "ok",
     "timestamp": 1602478435506,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "5taLY_ljgFq3"
   },
   "outputs": [],
   "source": [
    "\n",
    "input_shape =  (window_size, window_size, num_channels)\n",
    "model = clone_model(build_jigsawHSI(internal_size = filter_size,\n",
    "                      num_classes = output_units,\n",
    "                      verbose=1,\n",
    "                      dimension_filters=hsi_filters, # Was None,\n",
    "                      image_dim = input_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 32872,
     "status": "ok",
     "timestamp": 1602478436734,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "iVgd4QmzgKKq",
    "outputId": "32d4779c-5699-49b0-eaef-613ac3ef7968"
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model)\n",
    "plot_model(model, to_file=architecture_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32861,
     "status": "ok",
     "timestamp": 1602478436735,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OYsuViCjhSA3"
   },
   "outputs": [],
   "source": [
    "# Parallelize if gpus > 1\n",
    "if (max_gpus>1):\n",
    "    model = multi_gpu_model(model, gpus=max_gpus)\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=FuncOptimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 32854,
     "status": "ok",
     "timestamp": 1602478436736,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "sUQZa9UD-rsL"
   },
   "outputs": [],
   "source": [
    "# Saves the best model, based on accuracy\n",
    "checkpoint = ModelCheckpoint(best_model, monitor='accuracy', verbose=1, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no early stopping desired, skip this cell\n",
    "early_stop = EarlyStopping( monitor = 'loss',\n",
    "                           min_delta=0.001,\n",
    "                           mode='auto',\n",
    "                           verbose=1, patience=max_patience)\n",
    "callbacks_list = [checkpoint, early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize configuration\n",
    "config_txt  = f'Configuration for dataset [{dataset}]:\\n\\n'\n",
    "config_txt += f'Test Set Ratio: {test_ratio*100}% of samples\\n'\n",
    "config_txt += f'Window Size   : {window_size} pixels per side\\n'\n",
    "config_txt += f'Dim. Reduction: {dim_reduction} function\\n'\n",
    "config_txt += f'Num channels  : {num_channels} bands after {dim_reduction}\\n'\n",
    "config_txt += '# Network design\\n'\n",
    "config_txt += f'Input shape   : ({window_size}x{window_size}x{num_channels})\\n'\n",
    "config_txt += f'HSI Filters   : {hsi_filters} filters in first layer\\n'\n",
    "config_txt += f'Internal Size : ({filter_size}x{filter_size}) maximum network filter size\\n'\n",
    "config_txt += '# Training hyperparameters\\n'\n",
    "config_txt += f'Optimizer     : {optimizer_fn}\\n'\n",
    "config_txt += f'Learning rate : {optimizer_lr}\\n'\n",
    "config_txt += f'Batch Size    : {batch_size}\\n'\n",
    "config_txt += f'Num Epochs    : {max_epochs}\\n' \n",
    "config_txt += f'Patience      : {max_patience}\\n'\n",
    "config_txt += '# Training GPUs\\n'\n",
    "config_txt += f'GPU Maximum   : {max_gpus}\\n'\n",
    "print(config_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 417831,
     "status": "ok",
     "timestamp": 1602478821720,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "OVwsWGf1hfg3",
    "outputId": "66ced090-c536-4f79-9bee-71ded4683b4d"
   },
   "outputs": [],
   "source": [
    "# Fit the model keeping the history\n",
    "history = model.fit(x=Xtrain, y=ytrain, batch_size=batch_size, epochs=max_epochs, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5-BLNivkkD2"
   },
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 417824,
     "status": "ok",
     "timestamp": 1602478821723,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "rzi0kGwckZIh",
    "outputId": "860ced41-4c23-4c7b-d0d9-88b35f1d005f"
   },
   "outputs": [],
   "source": [
    "# Saves, but does not display, the history charts\n",
    "fig = plt.figure(figsize=(7,7)) \n",
    "plt.ioff()\n",
    "plt.grid() \n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epochs') \n",
    "plt.legend(['Training','Validation'], loc='upper right') \n",
    "plt.savefig(loss_curve) \n",
    "plt.close(fig)\n",
    "\n",
    "fig = plt.figure(figsize=(7,7)) \n",
    "plt.ioff()\n",
    "plt.ylim(np.min(history.history['accuracy']),1.05) \n",
    "plt.grid() \n",
    "plt.plot(history.history['accuracy'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.ylabel('Accuracy') \n",
    "plt.xlabel('Epochs') \n",
    "plt.legend(['Training','Validation']) \n",
    "plt.savefig(acc_curve) \n",
    "plt.close(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays history of training\n",
    "# loss and accuracy by epoch, side by side\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, figsize=(14, 7))\n",
    "ax1.grid() \n",
    "ax1.plot(history.history['loss'])\n",
    "ax1.set_ylabel('Loss') \n",
    "ax1.set_xlabel('Epochs') \n",
    "ax1.legend(['Training','Validation'], loc='upper right') \n",
    "\n",
    "ax2.set_ylim(np.min(history.history['accuracy']),1.05) \n",
    "ax2.grid() \n",
    "ax2.plot(history.history['accuracy'])\n",
    "ax2.set_ylabel('Accuracy') \n",
    "ax2.set_xlabel('Epochs') \n",
    "ax2.legend(['Training','Validation']) \n",
    "plt.show() # plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 418307,
     "status": "ok",
     "timestamp": 1602478822219,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "HKSPxOqckkD3"
   },
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(best_model)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=FuncOptimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418301,
     "status": "ok",
     "timestamp": 1602478822220,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tzGuqZILkkD5",
    "outputId": "58b28fd2-e2a8-47a5-94bd-3bb222491aa0"
   },
   "outputs": [],
   "source": [
    "Xtest = Xtest.reshape(-1, window_size, window_size, num_channels) #, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 418293,
     "status": "ok",
     "timestamp": 1602478822221,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "FIhcrDHQkkD7",
    "outputId": "301bc50b-063d-4ad4-b84e-96658ec5bfee"
   },
   "outputs": [],
   "source": [
    "Ytest = np_utils.to_categorical(ytest)\n",
    "Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 403
    },
    "executionInfo": {
     "elapsed": 427183,
     "status": "ok",
     "timestamp": 1602478831122,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "x9gnEB8wkkD-",
    "outputId": "38e44cce-3f72-40f7-b8e4-5914a2294f69"
   },
   "outputs": [],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test.shape) \n",
    "classification = classification_report(np.argmax(Ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 427171,
     "status": "ok",
     "timestamp": 1602478831123,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "M8Z-62eCkkEA"
   },
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_row_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_row_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 427165,
     "status": "ok",
     "timestamp": 1602478831124,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "Jw2j7mjQkkEC"
   },
   "outputs": [],
   "source": [
    "def get_targets(name):\n",
    "    targets_dict = {\n",
    "        'IP': ['Alfalfa', 'Corn-notill', 'Corn-mintill', 'Corn', 'Grass-pasture', 'Grass-trees', 'Grass-pasture-mowed',\n",
    "               'Hay-windrowed', 'Oats', 'Soybean-notill', 'Soybean-mintill', 'Soybean-clean', 'Wheat', 'Woods', \n",
    "               'Buildings-Grass-Trees-Drives', 'Stone-Steel-Towers'],\n",
    "        'SA': ['Brocoli_green_weeds_1', 'Brocoli_green_weeds_2', 'Fallow', 'Fallow_rough_plow', 'Fallow_smooth', 'Stubble',\n",
    "               'Celery','Grapes_untrained', 'Soil_vinyard_develop', 'Corn_senesced_green_weeds', 'Lettuce_romaine_4wk',\n",
    "               'Lettuce_romaine_5wk', 'Lettuce_romaine_6wk', 'Lettuce_romaine_7wk', 'Vinyard_untrained',\n",
    "               'Vinyard_vertical_trellis'],\n",
    "        'PU': ['Asphalt', 'Meadows', 'Gravel', 'Trees', 'Painted metal sheets', 'Bare Soil', 'Bitumen', 'Self-Blocking Bricks',\n",
    "               'Shadows']\n",
    "    }\n",
    "    targets = targets_dict.get(name)\n",
    "    return (targets)\n",
    "\n",
    "\n",
    "print(', '.join(get_targets(dataset[0:2].upper())))\n",
    "\n",
    "def reports (model, X_test, y_test, name, y_pred = None):\n",
    "    #start = time.time()\n",
    "    if (y_pred is None):\n",
    "        Y_pred = model.predict(X_test)\n",
    "        y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "    target_names = get_targets(name[0:2].upper())\n",
    "    print(\"Producing report\")\n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100, target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 445851,
     "status": "ok",
     "timestamp": 1602478849818,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "wiez8wEtkkEE",
    "outputId": "9955427d-ee60-4060-b1eb-9e79bbf5b67f"
   },
   "outputs": [],
   "source": [
    "(classification, confusion, Test_loss, Test_accuracy, \n",
    " oa, each_acc, aa, kappa, target_names) = reports(model, Xtest, Ytest, dataset[0:2], y_pred=y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_performance = 'Accuracy by target:\\n'\n",
    "for (a, b) in zip(target_names, each_acc):\n",
    "    target_performance += f'{b:8.4f} : {a}\\n'\n",
    "print(target_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "cf_matrix = np.asarray(confusion)\n",
    "sns_plot=sns.heatmap(cf_matrix, annot=False, xticklabels=target_names, yticklabels=target_names)\n",
    "sns_plot.figure.savefig(str(dataset)+'-heatmap.png', dpi=600)\n",
    "#plt.savefig(str(dataset)+'-heatmap.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 445840,
     "status": "ok",
     "timestamp": 1602478849819,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "kR-idaI8J5bl"
   },
   "outputs": [],
   "source": [
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "confusion=confusion.replace('\\n', '')\n",
    "confusion=confusion.replace('] [', ']\\n[')\n",
    "confusion=confusion.replace('][', ']\\n[')\n",
    "dim_reduction='pca'\n",
    "c_summary = 'Classification Summary\\n'\n",
    "c_summary += f'{Test_loss:7.3f} Test loss (%)\\n'\n",
    "c_summary += f'{Test_accuracy:7.3f} Test accuracy (%)\\n'\n",
    "c_summary += f'{kappa:7.3f} Kappa accuracy (%)\\n'\n",
    "c_summary += f'{oa:7.3f} Overall accuracy (%)\\n'\n",
    "c_summary += f'{aa:7.3f} Average accuracy (%)\\n\\n'\n",
    "\n",
    "c_summary += f'{classification}\\n\\n'\n",
    "c_summary += f'{confusion}\\n\\n'\n",
    "\n",
    "model_summary = []\n",
    "model.summary(print_fn=lambda x: model_summary.append(x)) # line_length=70,\n",
    "model_summary = '\\n'.join(model_summary)\n",
    "model_summary += '\\n\\n'\n",
    "\n",
    "print(c_summary)\n",
    "print(target_performance+'\\n\\n')\n",
    "print(model_summary)\n",
    "print(config_txt)\n",
    "\n",
    "with open(classification_file, 'w') as cs_file:\n",
    "    cs_file.write(c_summary)\n",
    "    cs_file.write(target_performance+'\\n\\n')\n",
    "    cs_file.write(model_summary)\n",
    "    cs_file.write(config_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 445833,
     "status": "ok",
     "timestamp": 1602478849820,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "xGcIixswkkEG"
   },
   "outputs": [],
   "source": [
    "def Patch(data, height_index, width_index, PATCH_SIZE):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 445826,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "r-HdxMrCkkEJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 445812,
     "status": "ok",
     "timestamp": 1602478849821,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "6GaaBm4BkkEL"
   },
   "outputs": [],
   "source": [
    "height = HSI_y.shape[0]\n",
    "width  = HSI_y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 470026,
     "status": "ok",
     "timestamp": 1602478874044,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "oumhazm3kkEN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 470018,
     "status": "ok",
     "timestamp": 1602478874046,
     "user": {
      "displayName": "Tanmay Chakraborty",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi7eevbipSJbPNmjfEacGnvwa7ZJkT_EcljzNX6FQ=s64",
      "userId": "10513402671331353489"
     },
     "user_tz": -330
    },
    "id": "tvZuH_0-kkEP"
   },
   "outputs": [],
   "source": [
    "X = padWithZeros(DRI, window_size//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4sHtc-12kkER"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "#for i in range(height):\n",
    "for i in tqdm(range(height), desc=\"Predicting...\",\n",
    "                          ascii=False, ncols=75):\n",
    "    for j in range(width):\n",
    "        target = int(HSI_y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X, i, j, window_size)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2]).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpnGO-c_kkET"
   },
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes = HSI_y,figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yIVQ8-hkkEW"
   },
   "outputs": [],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap, NoNorm\n",
    "\n",
    "cm = ListedColormap(np.array(spectral.spy_colors)/255.0)\n",
    "delta = (np.abs(outputs.astype(int) - HSI_y)>0)*1\n",
    "print('Misclassified pixels: ', np.sum(np.asarray(delta)>0), \"/\", delta.shape[0]*delta.shape[1])\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(15,8))\n",
    "ax1.set_title(\"Ground truth\")\n",
    "ax2.set_title(\"Prediction\")\n",
    "ax3.set_title(\"Delta\")\n",
    "ax1.imshow(HSI_y) #, cmap=cm, norm=NoNorm())\n",
    "ax2.imshow(outputs.astype(int)) #, cmap=cm, norm=NoNorm())\n",
    "ax3.imshow(delta, cmap=cm)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "vBPvnosekkEZ"
   },
   "outputs": [],
   "source": [
    "spectral.save_rgb(str(dataset)+\"-ground_truth.png\", HSI_y, colors=spectral.spy_colors)\n",
    "spectral.save_rgb(str(dataset)+\"-delta.png\", delta, colors=spectral.spy_colors)\n",
    "spectral.save_rgb(predictions_img, outputs.astype(int), colors=spectral.spy_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "#print(\"Keras Backend RESET\")  # optional\n",
    "#import keras\n",
    "#import gc\n",
    "#keras.backend.clear_session()\n",
    "#tf.keras.backend.clear_session()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JL4rV6j7kkEa"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyN/aVtrq8w9XQ9tKxeZX/5h",
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
